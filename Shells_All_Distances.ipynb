{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smarsland/pots/blob/master/Shells_All_Distances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3CGYNZXmlzg"
      },
      "source": [
        "# Shell Distances \n",
        "## Pairwise Distances Between Shell Contours\n",
        "\n",
        "The output of this notebook is the following three distance matrices based on the shell contours:\n",
        "1. Eigenshape distances\n",
        "1. SRVF Open (DP alg)\n",
        "1. SRVF Closed (Path-Straightening)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTnZL83Wmlzp"
      },
      "source": [
        "### Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fdasrsf==2.2.1 # Or fdasrsf==2.0.2 for closed curves\n",
        "# !pip install GPy # Might be needed when using Google colab to run code."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFtTSVdjmtWR",
        "outputId": "a5045cc4-d0d8-4a66-8d34-efed44af2b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fdasrsf\n",
            "  Downloading fdasrsf-2.3.10.tar.gz (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 7.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fdasrsf\n",
            "  Building wheel for fdasrsf (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fdasrsf: filename=fdasrsf-2.3.10-cp37-cp37m-linux_x86_64.whl size=1511230 sha256=22336b6b9de2b40015f892e596146091a038401b0651d69d72bcc27f4218973c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/ee/37/ca15430451efffbcb060a9cfff9eaf027b6c2048aa2fd5d35a\n",
            "Successfully built fdasrsf\n",
            "Installing collected packages: fdasrsf\n",
            "Successfully installed fdasrsf-2.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryA036rxmlzq"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK0fC2nDmlzs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from scipy.spatial import procrustes\n",
        "from geodesicDistances import geodDistance\n",
        "import tqdm\n",
        "from fdasrsf.geodesic import geod_sphere\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGz5d-pkmlzx"
      },
      "source": [
        "#### Original Contour Data & Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QMSWQCbmlzy"
      },
      "outputs": [],
      "source": [
        "pth = \"Shells_Final_Coords_Proc_UL.csv\"\n",
        "table = pd.read_csv(pth,header=None)\n",
        "dfinds = pd.read_csv('Shells_Index2.csv')\n",
        "indexshells = list(dfinds[\"Name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etweA-cmlzz"
      },
      "source": [
        "#### Re-format & Scale Contours\n",
        "\n",
        "Re-shaping the contour dataset and scaling again...just in case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97vGT05Kmlz1"
      },
      "outputs": [],
      "source": [
        "def rescale_shell(x,y):\n",
        "    p = max(max(y)-min(y),max(x)-min(x))\n",
        "    q = p/3\n",
        "    x_ = x/q\n",
        "    y_ = y/q\n",
        "    mp = min(x_)+(max(x_)-min(x_))/2\n",
        "    x_ = x_-mp\n",
        "    mp = min(y_)+(max(y_)-min(y_))/2\n",
        "    y_ = y_-mp\n",
        "    return x_,y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARZ7uVtRmlz3"
      },
      "outputs": [],
      "source": [
        "all_points = np.zeros((len(table),int(np.shape(table)[1]/2),2))\n",
        "n = len(table)\n",
        "for j in range(0,n):\n",
        "    coords = list(table.T[j])\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(0,len(coords)):\n",
        "        if i%2 == 0:\n",
        "            x.append(coords[i])\n",
        "        else:\n",
        "            y.append(coords[i])\n",
        "            \n",
        "    # x.append(x[0])\n",
        "    # y.append(y[0])\n",
        "    x,y = rescale_shell(np.array(x),np.array(y))\n",
        "    all_points[j,:,0] = list(x)\n",
        "    all_points[j,:,1] = list(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f46aRFWmlz5"
      },
      "source": [
        "## Distance Matrix 1 - Eigenshape\n",
        "\n",
        "Using SM's code from the Github repository, [pots](https://github.com/smarsland/pots)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPFBVYzZmlz9"
      },
      "outputs": [],
      "source": [
        "shells = deepcopy(all_points)\n",
        "\n",
        "npoints = np.shape(all_points)[1]\n",
        "nshells = len(table)\n",
        "\n",
        "newshells = np.zeros(np.shape(shells))\n",
        "for j in range(nshells):\n",
        "    mtx1, newshells[j,:,:], _ = procrustes(shells[0,:,:],shells[j,:,:])\n",
        "newshells/=np.max(newshells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJIvjHCNmlz-"
      },
      "outputs": [],
      "source": [
        "# Perform PCA\n",
        "shells = newshells.reshape([nshells,npoints*2])\n",
        "\n",
        "C = np.cov(shells.T)\n",
        "\n",
        "# Get the eigenvalues and eigenvectors\n",
        "evals,evecs = np.linalg.eig(C)\n",
        "\n",
        "# Now need to sort them into descending order\n",
        "indices = np.argsort(evals)\n",
        "indices = indices[::-1]\n",
        "evecs = evecs[:,indices]\n",
        "evals = evals[indices]\n",
        "evecs = np.real(evecs)\n",
        "evals = np.real(evals)\n",
        "m = np.mean(shells,axis=0).reshape((npoints,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92Wcagw-mlz_",
        "outputId": "c7ab1d7c-77ec-403e-c4d0-69b4143aceb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of dims to use: 38\n"
          ]
        }
      ],
      "source": [
        "# Screen plot of the cumulative sum of variances\n",
        "cs = np.cumsum(evals)\n",
        "cs /= cs[-1]\n",
        "varToSave = 0.98\n",
        "dims_to_use = np.where(cs>varToSave*cs[-1])[0][0]\n",
        "print(\"Number of dims to use: \"+str(dims_to_use))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ8y5jnsml0B"
      },
      "outputs": [],
      "source": [
        "ndims = [dims_to_use,22] # Save results from 22 dimensions too as that was the previous top performing DM for the KNN.\n",
        "\n",
        "for ndim in ndims:\n",
        "    m = np.mean(shells,axis=0)\n",
        "    b = np.zeros((nshells,ndim))\n",
        "    for i in range(nshells):\n",
        "        P = evecs[:,:ndim]\n",
        "        b[i,:] = np.dot(P.T,(shells[i,:]-m))\n",
        "    dists = np.zeros((nshells,nshells))\n",
        "    for i in range(nshells):\n",
        "        for j in range(i,nshells):\n",
        "            dists[i,j] = np.linalg.norm(b[i,:]-b[j,])\n",
        "            dists[j,i] = np.linalg.norm(b[i,:]-b[j,])\n",
        "    test = pd.DataFrame(dists,index=indexshells)\n",
        "    test.columns = indexshells\n",
        "    test.index.Name = 'Name'\n",
        "    test.to_csv('Eigenshape_shells'+str(ndim)+'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QWC_tcJml0C"
      },
      "source": [
        "## Distance Matrix 2 - SRVF _Open_\n",
        "\n",
        "Geodesic distance using [fdasrsf](https://fdasrsf-python.readthedocs.io/en/latest/])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hydTBcW_ml0C",
        "outputId": "7efe3885-678b-46ff-dc8a-eda73a88c541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [2:17:36<00:00, 35.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed distances between 235 contours, with 0 errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "distances_DP = np.zeros((n,n))\n",
        "errors = []\n",
        "\n",
        "for i in tqdm.tqdm(range(0,n)):\n",
        "    \n",
        "    x1 = list(all_points[i,:,0])[:-1]\n",
        "    y1 = list(all_points[i,:,1])[:-1]\n",
        "    \n",
        "    beta1 = np.column_stack([x1,y1]).T\n",
        "\n",
        "    for j in range(i+1,n):\n",
        "      x2 = list(all_points[j,:,0])[:-1]\n",
        "      y2 = list(all_points[j,:,1])[:-1]\n",
        "        \n",
        "      beta2 = np.column_stack([x2,y2]).T\n",
        "        \n",
        "      try:\n",
        "          d,_,_, = geod_sphere(beta2, beta1)\n",
        "      except:\n",
        "          try:\n",
        "              d,_,_, = geod_sphere(beta2, beta1)\n",
        "          except:\n",
        "              print(\"Error for contours \"+str(i)+\" and \"+str(j))\n",
        "              errors.append([i,j])\n",
        "              d = 100000\n",
        "                \n",
        "      distances_DP[i,j] = d\n",
        "      distances_DP[j,i] = d\n",
        "        \n",
        "    pd.DataFrame(distances_DP).to_csv('SRVF_Open_shells_distances.csv')\n",
        "\n",
        "print(\"Computed distances between \"+str(n)+\" contours, with \"+str(len(errors))+\" errors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSYq-62Mml0D"
      },
      "outputs": [],
      "source": [
        "distancesDF = pd.DataFrame(distances_DP,index=indexshells)\n",
        "distancesDF.columns = indexshells\n",
        "distancesDF.index.name='Name'\n",
        "distancesDF.to_csv('SRVF_Open_shells.csv')\n",
        "from google.colab import files\n",
        "files.download('SRVF_Open_shells.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlmoAEzml0D"
      },
      "source": [
        "## Distance Matrix 3 - SRVF _Closed_\n",
        "\n",
        "Using the Path-Straightening algorithm, implemented in [fdasrsf](https://fdasrsf-python.readthedocs.io/en/latest/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnOEHoivml0E",
        "outputId": "7634e7b3-027b-4f2b-cfc8-f563ae89d054"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|████▍                                                                      | 14/235 [1:17:31<20:27:41, 333.31s/it]"
          ]
        }
      ],
      "source": [
        "distances = np.zeros((n,n))\n",
        "errors = []\n",
        "\n",
        "for i in tqdm.tqdm(range(0,n)):\n",
        "    x1 = list(all_points[i,:,0])\n",
        "    y1 = list(all_points[i,:,1])\n",
        "\n",
        "    for j in range(i+1,n):\n",
        "        x2 = list(all_points[j,:,0])\n",
        "        y2 = list(all_points[j,:,1])\n",
        "                \n",
        "        try:\n",
        "            d,_,_,_ = geodDistance(x1,y1,x2,y2,k=2)\n",
        "        except:\n",
        "            try:\n",
        "                d,_,_,_ = geodDistance(x2,y2,x1,y1,k=2)\n",
        "            except:\n",
        "                print(\"Error for contours \"+str(i)+\" and \"+str(j))\n",
        "                errors.append([i,j])\n",
        "                d = 100000\n",
        "                \n",
        "        distances[i,j] = d\n",
        "        distances[j,i] = d\n",
        "        \n",
        "    pd.DataFrame(distances).to_csv('SRVF_Closed_shells_distances.csv')\n",
        "\n",
        "print(\"Computed distances between \"+str(n)+\" contours, with \"+str(len(errors))+\" errors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAbRtgitml0E"
      },
      "outputs": [],
      "source": [
        "distancesDF = pd.DataFrame(distances,index=indexshells)\n",
        "distancesDF.columns = indexshells\n",
        "distancesDF.index.name='Name'\n",
        "distancesDF.to_csv('SRVF_Closed_shells.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AV6dYnTvtzVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Shells_All_Distances.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}