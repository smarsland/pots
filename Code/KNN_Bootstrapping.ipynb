{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Bootstrapping\n",
    "\n",
    "__Aim__: We wish to find the best method to compute distances by looking at the resulting F1 score from KNN done on that distance matrix.\n",
    "\n",
    "__Datasets__: We wish to find the best method for each dataset;\n",
    "1. Athenian pots,\n",
    "1. Shells,\n",
    "1. Swedish leaves.\n",
    "\n",
    "__Distance Methods__: We will look at 5 main methods, with some of them holding different variations. In total, we will look at 51 methods (distance matrices).\n",
    "1. SRVF (Path-Straightening)\n",
    "1. Eigenshape, with PCs holding the following percentages of the variance;\n",
    "    - 75%\n",
    "    - 80%\n",
    "    - 85%\n",
    "    - 90%\n",
    "    - 92.5%\n",
    "    - 95%\n",
    "    - 98%\n",
    "    - 99% \n",
    "    - 99.5%\n",
    "    - 99.9%\n",
    "1. LDDMM\n",
    "    - Slow\n",
    "    - Moderate\n",
    "    - Quick\n",
    "1. Currents; \n",
    "    - Here we will use 36 different variations of the Currents algorithm.\n",
    "1. L2.\n",
    "\n",
    "__Bootstrapping Method__: We have the same training set size for each of the species in each of the datasets. We have 20 per specie in the Pots and Leaves datasets and we have 12 in the Shells datasets. We go through each specie and select 20 (or 12 resp.) shapes from that specie randomly. We do the same for each specie. Then we'll run the KNN algorithm using each of the 51 distance matrices, for K values 1-10, and we'll output the best F1 score from the various KNN results, per distance matrix. We then repeat this process by selecting a new randomly generated test and training set. We do this 100 times.\n",
    "\n",
    "__Final Output__: In the end, we will have 100 different \"best F1\" scores for each 51 methods, for each of the three datasets. We will finalise our test by computing the mean, standard deviation, and confidence intervals over the 100 variations, for each of the 51 methods, for each dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from tqdm import notebook as tqdm\n",
    "import re\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index Data\n",
    "table = pd.read_csv(\"Final_Vase_Index.csv\")\n",
    "\n",
    "# Unique genus/species\n",
    "specs = list(np.unique(list(table[\"Specie\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"C:\\\\Users\\\\arian\\\\Documents\\\\GitHub\\\\Pots\\\\Code\\\\DistMats\\\\Pots\"\n",
    "files = []\n",
    "for file in os.listdir(pth):\n",
    "    files.append(file)\n",
    "    \n",
    "ntot = len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for computing the mode, when there are more than one cadidates for the mode.\n",
    "# It ouputs all the options for the mode values.\n",
    "\n",
    "def multi_mode(lst):\n",
    "    p = Counter(lst).most_common(1)[0][1]\n",
    "    modes = [val[0] for val in Counter(lst).most_common() if val[1] == p]\n",
    "    return modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddbdac04c704f68b836053a54995214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nboots = 100\n",
    "\n",
    "all_scores = np.zeros((ntot,nboots))\n",
    "top_neighs = np.zeros((ntot,nboots))\n",
    "\n",
    "k_neighbours = [3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "\n",
    "for nb in tqdm.tqdm(range(0,nboots)):\n",
    "    \n",
    "    # 1) Create training and test sets:\n",
    "    train_names = []\n",
    "    test_names = []\n",
    "\n",
    "    for n,sp in enumerate(specs):\n",
    "        inds = list(table[table[\"Specie\"]==sp][\"Index\"])\n",
    "        randinds = random.sample(inds, 20)\n",
    "        testnames = list(table[\"Name\"][list(np.setdiff1d(inds,randinds))])\n",
    "        trainnames = list(table[\"Name\"][randinds])\n",
    "        train_names.extend(trainnames)\n",
    "        test_names.extend(testnames)\n",
    "        \n",
    "    # 2) Save training and test sets:\n",
    "    if nb == 0:\n",
    "        pd.DataFrame(train_names).to_csv('training_vases.csv',index=False)\n",
    "        pd.DataFrame(test_names).to_csv('testing_vases.csv',index=False)\n",
    "    else:\n",
    "        df = pd.read_csv('training_vases.csv')\n",
    "        df.insert(len(df.T), len(df.T), train_names, True) \n",
    "        df.to_csv('training_vases.csv',index=False)\n",
    "        df = pd.read_csv('testing_vases.csv')\n",
    "        df.insert(len(df.T), len(df.T), test_names, True) \n",
    "        df.to_csv('testing_vases.csv',index=False)\n",
    "        \n",
    "    # 3) (Iterate through) Get distance matrices:\n",
    "    \n",
    "    pth = \"C:\\\\Users\\\\arian\\\\Documents\\\\GitHub\\\\Pots\\\\Code\\\\DistMats\\\\Pots\"\n",
    "    n_f = 0\n",
    "    for file in os.listdir(pth):\n",
    "        all_dists = pd.read_csv(pth+\"\\\\\"+file)\n",
    "        all_dists = all_dists.set_index('Name')\n",
    "        \n",
    "    # 4) KNN using K = 3,...,12.\n",
    "        \n",
    "        scores_sp = []\n",
    "\n",
    "        for neigh in k_neighbours:\n",
    "\n",
    "            # This will be updated during the Knn algorithm to contain the list of all the pots and their predicted sample.\n",
    "            # To start with, it only contains the details from the training sample.\n",
    "            specie_details = {}\n",
    "            for shell in train_names:\n",
    "                specie_details.update({shell:{\"Specie\":list(table[table[\"Name\"]==shell][\"Specie\"])[0]}})\n",
    "\n",
    "            for test in test_names:\n",
    "                dists = []\n",
    "                for train in train_names:\n",
    "                    d = all_dists[test][train]\n",
    "                    dists.append(d)\n",
    "                toprnk = np.argsort(dists)[:neigh]\n",
    "                top_classes = []\n",
    "                for ind in toprnk:\n",
    "                    top_classes.append(specie_details[train_names[ind]][\"Specie\"])\n",
    "                try:\n",
    "                    shapeclass = mode(top_classes)\n",
    "                except:\n",
    "                    # If there are multiple choices for the mode, we pick the one with the smallest distance.\n",
    "                    modes = multi_mode(top_classes)\n",
    "                    md_k = [n for n,val in enumerate(top_classes) if val in modes][0]\n",
    "                    shapeclass = top_classes[md_k]\n",
    "\n",
    "                specie_details.update({test:{\"Specie\":shapeclass}})\n",
    "\n",
    "            act_specie = []\n",
    "            pred_specie = []\n",
    "\n",
    "            for testshape in test_names:\n",
    "                pred_sp = int(specie_details[testshape][\"Specie\"])\n",
    "                act_sp = int(list(table[table[\"Name\"]==testshape][\"Specie\"])[0])\n",
    "\n",
    "                act_specie.append(act_sp)\n",
    "                pred_specie.append(pred_sp)\n",
    "\n",
    "            f1 = f1_score(act_specie, pred_specie, average='weighted')\n",
    "            scores_sp.append(f1)  \n",
    "\n",
    "    # 5) Save top F1 score\n",
    "        all_scores[n_f,nb] = max(scores_sp)\n",
    "        top_neighs[n_f,nb] = k_neighbours[np.argmax(scores_sp)]\n",
    "        n_f = n_f+1\n",
    "        \n",
    "    \n",
    "\n",
    "dfscores = pd.DataFrame(all_scores)\n",
    "dfscores.insert(0, \"Method\", files, True) \n",
    "dfscores.to_csv('All_Scores_Vases.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
